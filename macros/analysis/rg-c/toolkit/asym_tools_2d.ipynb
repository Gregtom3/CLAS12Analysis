{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "physical-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "# Get all target polarizations from RCDB\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append(\"/work/clas12/users/gmat/packages/clas12root/rcdb/python/\")\n",
    "import rcdb\n",
    "from rcdb.provider import RCDBProvider\n",
    "from rcdb.model import ConditionType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-shell",
   "metadata": {},
   "source": [
    "# Set the Cook Version\n",
    "---\n",
    "Options\n",
    "- \"0\" (../ana_data/dst/...)\n",
    "- \"8.3.2\" (../ana_data/8.3.2/dst/...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bearing-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "version=\"8.3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-schedule",
   "metadata": {},
   "source": [
    "# Correction\n",
    "---\n",
    "RAW::scaler had bugs which I think I've solved as of 9/18/2022\n",
    "In this case, the correction flag parameter will change the fcup calculation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-notification",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RCDBProvider' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a59ac37b4018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRCDBProvider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mysql://rcdb@clasdb/rcdb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m18000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mglobpar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RCDBProvider' is not defined"
     ]
    }
   ],
   "source": [
    "db = RCDBProvider(\"mysql://rcdb@clasdb/rcdb\")\n",
    "rmin = 16000\n",
    "rmax = 18000\n",
    "rlist = []\n",
    "globpar = \"\"\n",
    "if(version==\"0\"):\n",
    "    globpar=\"/volatile/clas12/rg-c/production/ana_data/*BT/dst/train/sidisdvcs/*.hipo\"\n",
    "elif(version==\"8.3.2\"):\n",
    "    globpar=\"/volatile/clas12/rg-c/production/ana_data/*BT/8.3.2/dst/train/sidisdvcs/*.hipo\"\n",
    "else:\n",
    "    print(\"UNKNOWN VERSION\")\n",
    "    \n",
    "for path in glob.glob(globpar):\n",
    "    path=str(path)\n",
    "    runloc = path.index('sidisdvcs/sidisdvcs')\n",
    "    start = path.index('_',runloc)\n",
    "    end = path.index('.hipo',runloc)\n",
    "    runNumber = int(path[start+1:end])\n",
    "    if(rmin<runNumber and rmax>runNumber):\n",
    "        rlist.append(runNumber)\n",
    "rlist=np.array(rlist)\n",
    "rmin=np.amin(rlist)\n",
    "rmax=np.amax(rlist)\n",
    "\n",
    "_rcdb_run = np.arange(rmin,rmax+1)\n",
    "_rcdb_Tpol = np.zeros(len(_rcdb_run))\n",
    "for i in range(len(_rcdb_run)):\n",
    "    run = db.get_run(_rcdb_run[i])\n",
    "    if(run):\n",
    "        target_pol_cnd = run.get_condition('target_polarization')\n",
    "        if(target_pol_cnd):\n",
    "            _rcdb_Tpol[i] = target_pol_cnd.value\n",
    "        else:\n",
    "            _rcdb_Tpol[i] = 0.0\n",
    "    else:\n",
    "        _rcdb_Tpol[i] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-woman",
   "metadata": {},
   "source": [
    "# PARAMETERS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "foreign-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAttMarkers = [20,21,22,23,33,34,29,24,25,26,32,27,28,30]\n",
    "TColors = [1,2,9,8,6]\n",
    "MarkerSize = 2\n",
    "\n",
    "# Webplotdigitizer using Harut's MC data\n",
    "# https://userweb.jlab.org/~avakian/tmp/2022-SIDIS-Aug8.pdf\n",
    "# A_LL_proton as a function of x\n",
    "# [x,A_LL_proton]\n",
    "A_LL_proton = np.array([\n",
    "[0.11757848013262741, 0.18379497577967974],\n",
    "[0.1926541526284828, 0.2684978538773837],\n",
    "[0.2672720466335098, 0.34164975653604424],\n",
    "[0.3428054976201935, 0.3981517312610664],\n",
    "[0.4178811701160489, 0.4407159649813103],\n",
    "[0.4929568426119043, 0.4885217883139879],\n",
    "[0.5675747366169313, 0.5337541806020067],\n",
    "[0.6426504091127867, 0.602493032329989]])\n",
    "\n",
    "# Webplot digitizer using Harut's MC data\n",
    "# https://userweb.jlab.org/~avakian/tmp/2022-SIDIS-Aug8.pdf\n",
    "# NH3 dilution factor f as a function of x\n",
    "# [x,f]\n",
    "f_NH3 = np.array([\n",
    "[0.117026744250078, 0.177177027261547],\n",
    "[0.12562822371923127, 0.17772179947569455],\n",
    "[0.1342297031883845, 0.17830842392982116],\n",
    "[0.14290937792543915, 0.1788241341617871],\n",
    "[0.15111988105508545, 0.17935517777492244],\n",
    "[0.16003414159584425, 0.17997120009544962],\n",
    "[0.16863562106499752, 0.18047914233841564],\n",
    "[0.17739349106995356, 0.18102689485856938],\n",
    "[0.18583858000330403, 0.1815937981106982],\n",
    "[0.19444005947245727, 0.18207997718887511],\n",
    "[0.20304153894161053, 0.18264986074701012],\n",
    "[0.21195579948236934, 0.18323909763395071],\n",
    "[0.220244497879917, 0.18375614607129687],\n",
    "[0.2286895868132675, 0.1843021232034362],\n",
    "[0.23744745681822355, 0.1848373200515962],\n",
    "[0.245892545751574, 0.18539417876613007],\n",
    "[0.25465041575653, 0.18593523492788716],\n",
    "[0.26325189522568326, 0.1865720820699886],\n",
    "[0.27154059362323096, 0.18699956671377962],\n",
    "[0.2804548541639898, 0.1876155890343068],\n",
    "[0.28905633363314304, 0.1881478055764606],\n",
    "[0.2976578131022963, 0.1887428004785831],\n",
    "[0.3058248744164418, 0.1891597826685512],\n",
    "[0.3151214229336074, 0.1897605829769269],\n",
    "[0.32330586097395325, 0.1902669950806733],\n",
    "[0.3319768473479078, 0.19083420400521306],\n",
    "[0.3406652104480625, 0.19139969796535447],\n",
    "[0.34895390884561023, 0.19186317553552745],\n",
    "[0.35778997411846764, 0.19246054828466017],\n",
    "[0.36670423465922647, 0.19303053314121038],\n",
    "[0.37514932359257697, 0.1935346580333707],\n",
    "[0.3844545604728427, 0.19416775713410842],\n",
    "[0.3927953890489913, 0.19470988729602234],\n",
    "[0.4014229336074451, 0.19526162007378994],\n",
    "[0.4099983479872978, 0.1958152425705318],\n",
    "[0.4188604783494557, 0.19637195733468613],\n",
    "[0.42798325960461825, 0.1969587506195048],\n",
    "[0.43598524201986083, 0.19745540786358048],\n",
    "[0.44562063669793245, 0.19807052442225448],\n",
    "[0.45404834890508267, 0.19859524428929248],\n",
    "[0.46335358578534847, 0.199194861598047],\n",
    "[0.4713381914743907, 0.19967202867159828],\n",
    "[0.48063473999155637, 0.20033235216572196],\n",
    "[0.4895490005323152, 0.20092158905266255],\n",
    "[0.49783769892986285, 0.20136330345804643],\n",
    "[0.5063609831311147, 0.2019388117439748],\n",
    "[0.5150406578681693, 0.202477959230329],\n",
    "[0.5237985278731254, 0.2030684010352613],\n",
    "[0.5322436168064758, 0.20361772634659897],\n",
    "[0.5407473521907523, 0.2041412792085024],\n",
    "[0.5491337946731768, 0.20470968061087763],\n",
    "[0.5576136370589279, 0.20522004809192537],\n",
    "[0.5682134400411167, 0.20591869319120468],\n",
    "[0.57681491951027, 0.20633790868541513],\n",
    "[0.5854163989794232, 0.2069329035875375],\n",
    "[0.5941742689843793, 0.20750576745167867],\n",
    "[0.6026193579177297, 0.20800570711984107],\n",
    "[0.6112208373868829, 0.20856722022998025],\n",
    "[0.6198223168560363, 0.20911199244412781],\n",
    "[0.6284237963251895, 0.209673505554267],\n",
    "[0.6370252757943428, 0.2101931664244271],\n",
    "[0.645235778923989, 0.21074346206795286]])\n",
    "\n",
    "f_ND3 = np.array([[0.11730854875854804, 0.05148147554387039],\n",
    "[0.19270740918757046, 0.10740272856982569],\n",
    "[0.26750211208110397, 0.1724154736521477],\n",
    "[0.343082219770773, 0.2320762460522311],\n",
    "[0.41787692266430654, 0.281128371746709],\n",
    "[0.4930643279559077, 0.3371361559549197],\n",
    "[0.568251733247509, 0.3973012488577525],\n",
    "[0.6434391385391103, 0.47910752360645814],\n",
    "])\n",
    "\n",
    "def interp(model,x):\n",
    "    f = interpolate.interp1d(model[:,0], model[:,1], fill_value='extrapolate')\n",
    "    a=f(x)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "naughty-suite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65 0.7  0.75]\n"
     ]
    }
   ],
   "source": [
    "A_LL_proton_sebastian = pd.read_csv(\"./toolkit/sebastian_A_LL_p.txt\",sep=\" \",names=[\"xmin\",\"xmax\",\"Q2min\",\"Q2max\",\"A_LL\"])\n",
    "A_LL_deuteron_sebastian = pd.read_csv(\"./toolkit/sebastian_A_LL_d.txt\",sep=\" \",names=[\"xmin\",\"xmax\",\"Q2min\",\"Q2max\",\"A_LL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-internship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reliable-learning",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return list of files for analysis\n",
    "# Consecutive flag reorganizes file list with increasing run number\n",
    "def get_files(rootdir = \"\", target = \"\",runMin = -1,runMax = -1, runList = [], consecutive=True, monteCarlo=False):\n",
    "    files = []\n",
    "    runs = []\n",
    "    for path in Path(rootdir).glob(\"*.root\"):\n",
    "        runNumber = get_run_from_root(str(path))\n",
    "        if((runMin < 0 and runMax < 0 and runList==[]) or (runNumber >= runMin and runNumber <= runMax) or (runNumber in runList) or monteCarlo==True):\n",
    "            tfile = ROOT.TFile(str(path),\"READ\")\n",
    "            if(tfile.GetListOfKeys().Contains(\"tree_postprocess\")):\n",
    "                files.append(str(path))\n",
    "                runs.append(runNumber)\n",
    "            else:\n",
    "                print(\"ERROR: get_files() found a .root file (run\",runNumber,\") without a tree_reco...skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Sort by runNumber if specified\n",
    "    if(consecutive==True):\n",
    "        files = [x for y, x in sorted(zip(runs, files))]\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab location of rcdb.csv\n",
    "def get_rcdb(rootdir = \"\"):\n",
    "    rcdb_file = rootdir + \"rcdb.csv\"\n",
    "    if(not os.path.exists(rcdb_file)):\n",
    "        print(\"ERROR: get_rcdb() cannot find file\",rcdb_file,\". Aborting...\")\n",
    "        return -1\n",
    "    return rcdb_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "yellow-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the run number from root file name\n",
    "def get_run_from_root(file):\n",
    "    start = file.index('/run')\n",
    "    end = file.index('.',start)\n",
    "    runNumber = int(file[start+4:end])\n",
    "    return runNumber\n",
    "\n",
    "# Extract other column value based on runNumber\n",
    "def get_colval_from_run(rcdb_csv,runNumber,col = ''):\n",
    "    return rcdb_csv.query('Run=={}'.format(runNumber))[col].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "healthy-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CLAS12Analysis/util/runChargeAsymmetry.csv determine faraday cup accumulation for...\n",
    "# helicity = parallel to target\n",
    "# helicity = antiparallel to target\n",
    "\n",
    "def chargeAsymWeights(file,HWP,Tpol,correction):\n",
    "    \n",
    "    runNumber = get_run_from_root(file)\n",
    "    #rCA_df = pd.read_csv('../../../util/runHelicityCounts.csv')\n",
    "    # Check if this run has had chargeAsymmetry calculated for it\n",
    "    #if(np.sum(rCA_df['Run']==runNumber)==0):\n",
    "    #    print(\"ERROR: Run\",runNumber,\"does not appear in CLAS12Analysis/util/runHelicityCounts.csv...Aborting...\")\n",
    "    #    return -1\n",
    "\n",
    "    # Get accumulated Faraday cup charge for + and - helicity\n",
    "    # Obtained via HEL::scaler in recon banks\n",
    "    fcup_pos,fcup_neg = 0,0\n",
    "    scaler_dir=\"\"\n",
    "    if(version==\"0\"):\n",
    "        scaler_dir=\"/volatile/clas12/users/gmat/clas12analysis.sidis.data/rgc-scaler/run{}_HELScaler-all.csv\".format(runNumber)\n",
    "    elif(version==\"8.3.2\"):\n",
    "        scaler_dir=\"/volatile/clas12/users/gmat/clas12analysis.sidis.data/rgc-scaler8.3.2/run{}_HELScaler-all.csv\".format(runNumber)\n",
    "    else:\n",
    "        print(\"UNKNOWN VERSION\")\n",
    "        \n",
    "    if(correction==True):\n",
    "        #df_hel = pd.read_csv(\"/volatile/clas12/users/gmat/clas12analysis.sidis.data/rgc-scaler/run{}_HELScaler.csv\".format(runNumber),header=None,names=[\"run\",\"fileidx\",\"entries\",\"fcupgated_total\",\"fcupgated_total_pos\",\n",
    "        #                          \"fcupgated_total_neg\",\"fcupgated_total_zero\",\"raw_fcupgated_total\",\n",
    "        #                          \"raw_fcupgated_total_pos\",\"raw_fcupgated_total_neg\",\"raw_fcupgated_total_zero\"])\n",
    "        #fcup_pos = np.sum(df_hel[\"raw_fcupgated_total_pos\"].to_numpy())\n",
    "        #fcup_neg = np.sum(df_hel[\"raw_fcupgated_total_neg\"].to_numpy())\n",
    "        df_hel = pd.read_csv(scaler_dir)\n",
    "        fcup_pos = np.sum(df_hel[df_hel.helicity==1].fcupgated_33ms.to_numpy())\n",
    "        fcup_neg = np.sum(df_hel[df_hel.helicity==-1].fcupgated_33ms.to_numpy())\n",
    "    elif(correction==False):\n",
    "        df_hel = pd.read_csv(scaler_dir)\n",
    "        fcup_pos = np.sum(df_hel[df_hel.helicity==1].fcupgated.to_numpy())\n",
    "        fcup_neg = np.sum(df_hel[df_hel.helicity==-1].fcupgated.to_numpy())\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Need correction or don't. You must specify my good researcher\")\n",
    "        return -1\n",
    "        \n",
    "    #Tpol = 1\n",
    "    if(fcup_pos == 0 or fcup_neg == 0):\n",
    "        print(\"ERROR: Zero fcup charge (not all runs currently have this)...setting to 1\")\n",
    "        return 1,1\n",
    "    elif(HWP==1): # HWP out\n",
    "        if(Tpol>0):\n",
    "            return fcup_pos, fcup_neg\n",
    "        else:\n",
    "            return fcup_neg, fcup_pos\n",
    "    elif(HWP==0): # HWP in\n",
    "        if(Tpol>0):\n",
    "            return fcup_neg, fcup_pos\n",
    "        else:\n",
    "            return fcup_pos, fcup_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "outer-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an RDataFrame Histo2D\n",
    "def hist2d(df,direction,name,xbins,ybins):\n",
    "    zhat = 1 # Pointing from target to CLAS12\n",
    "    histo2d = df.Define(\"vz\",\"abs(vz_e+4.5)\").Filter(\"helicity=={} && p_e > 2.6 && th_e > 0.14 && th_e < 0.611 && vz < 4\".format(zhat*direction)).Histo2D((name,\"\",len(xbins)-1,xbins,len(ybins)-1,ybins),\"x\",\"Q2\")\n",
    "    return histo2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAxes(tg,axes):\n",
    "    tg.GetXaxis().SetLimits(axes[0],axes[1])\n",
    "    tg.GetYaxis().SetRangeUser(axes[2],axes[3])\n",
    "    tg.GetYaxis().SetLimits(axes[2],axes[3])\n",
    "    return tg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-circle",
   "metadata": {},
   "source": [
    "# UNWEIGHTED AND WEIGHTED A_LL\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "gross-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given run, compute the A_LL\n",
    "def get_A_LL_hist(file,runNumber,df_rcdb,target,xbins,ybins,correction=False):\n",
    "    # Determine polarization direction of the target\n",
    "    Tpol = 0\n",
    "    targetPol = get_colval_from_run(df_rcdb,runNumber,'Tpol')\n",
    "    HWP = get_colval_from_run(df_rcdb,runNumber,'HWP')\n",
    "\n",
    "    if(targetPol>0):# Extract \n",
    "        Tpol = 1\n",
    "    else:\n",
    "        Tpol = -1\n",
    "    \n",
    "    if(HWP==0): #If the HWP is in, artificially flip Tpol sign\n",
    "        Tpol = Tpol * -1\n",
    "    \n",
    "    # ************************************************************\n",
    "    # TEMPORARY PROGRAM AS OF SEPTEMBER 19TH 2022\n",
    "    # Flip Tpol b/c some HWP status' are buggy\n",
    "    # ************************************************************\n",
    "    if(version==\"0\"):\n",
    "        if(runNumber in [16414 , 16416 , 16419 , 16421 , 16422 , 16423 , 16424 , 16426 , 16432] or\n",
    "           runNumber in [16473 , 16475 , 16482 , 16483 , 16484]):\n",
    "            Tpol = Tpol * -1\n",
    "    elif(version==\"8.3.2\"):\n",
    "        if(runNumber in [16300, 16309, 16681, 16720, 16726, 16728, 16750, 16762, 16768,\n",
    "       16979, 17015, 17019, 17118, 17076, 17144]):\n",
    "            Tpol = Tpol * -1\n",
    "    \n",
    "    fcup_parallel, fcup_antiparallel = chargeAsymWeights(file,HWP,Tpol,correction)\n",
    "    \n",
    "    if(fcup_parallel==False):\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Create RDataframe from file\n",
    "    ROOT.EnableImplicitMT()\n",
    "    df = ROOT.RDataFrame(\"tree_postprocess\",file)\n",
    "    \n",
    "    # Create histograms for anti-parallel/parallel events\n",
    "    h_ap = hist2d(df,-Tpol,\"h_{}_antiparallel\".format(runNumber),xbins,ybins)\n",
    "    h_p = hist2d(df,Tpol,\"h_{}_parallel\".format(runNumber),xbins,ybins)\n",
    "    \n",
    "    \n",
    "    # Process histograms (from Histo1D --> TH1D)\n",
    "    H_ap = h_ap.GetValue().Clone()\n",
    "    H_p = h_p.GetValue().Clone()\n",
    "    Hw_ap = h_ap.GetValue().Clone() # To be weighted by beam Charge Asym\n",
    "    Hw_p = h_p.GetValue().Clone()   # To be weighted by beam Charge Asym\n",
    "    \n",
    "    H_ap.Sumw2()\n",
    "    H_p.Sumw2()\n",
    "    Hw_ap.Sumw2()\n",
    "    Hw_p.Sumw2()\n",
    "    \n",
    "    \n",
    "    Hw_ap.Scale(1/fcup_antiparallel)\n",
    "    Hw_p.Scale(1/fcup_parallel)\n",
    "\n",
    "    \n",
    "    # Grab N+ and N- along with their errors\n",
    "    N_p = [H_p.GetBinContent(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    N_m = [H_ap.GetBinContent(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    Nw_p = [Hw_p.GetBinContent(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    Nw_m = [Hw_ap.GetBinContent(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    \n",
    "    N_err_p = [H_p.GetBinError(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    N_err_m = [H_ap.GetBinError(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    Nw_err_p = [Hw_p.GetBinError(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    Nw_err_m = [Hw_ap.GetBinError(i+1,j+1) for i in range(H_p.GetNbinsX()) for j in range(H_p.GetNbinsY())]\n",
    "    \n",
    "    # Scale by float to avoid division issues\n",
    "    H_ap.Scale(1.0)\n",
    "    H_p.Scale(1.0)\n",
    "    \n",
    "    # Create numerator and denominator histogram\n",
    "    H_numerator = H_p.Clone()\n",
    "    H_denominator = H_p.Clone()\n",
    "    Hw_numerator = Hw_p.Clone()\n",
    "    Hw_denominator = Hw_p.Clone()\n",
    "    \n",
    "    # Construct numerator and denominator of asymmetry\n",
    "    H_numerator.Add(H_ap,-1)\n",
    "    H_denominator.Add(H_ap,1)\n",
    "    Hw_numerator.Add(Hw_ap,-1)\n",
    "    Hw_denominator.Add(Hw_ap,1)\n",
    "    \n",
    "    # Divide numerator and denominator\n",
    "    H = H_numerator.Clone()\n",
    "    H.Divide(H_denominator)\n",
    "    Hw = Hw_numerator.Clone()\n",
    "    Hw.Divide(Hw_denominator)\n",
    "    \n",
    "    # Label Histogram\n",
    "    H.SetTitle(\"{} asymmetries RG-C;{};{}\".format(target,\"x\",\"Q^{2}[GeV^{2}]\")+\"(N^{+}-N^{-})/(N^{+}+N^{-})\")\n",
    "    Hw.SetTitle(\"{} asymmetries RG-C;{};\".format(target,\"x\",\"Q^{2}[GeV^{2}]\")+\"(L^{-}N^{+}-L^{+}N^{-})/(L^{-}N^{+}+L^{+}N^{-})\")\n",
    "    \n",
    "    # Return run and H\n",
    "    return [runNumber,target,targetPol,HWP,H.Clone(),Hw.Clone(),fcup_parallel,fcup_antiparallel,N_p,N_m,N_err_p,N_err_m,Nw_p,Nw_m,Nw_err_p,Nw_err_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-denver",
   "metadata": {},
   "source": [
    "# MAIN CODE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "covered-surfing",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-8923fdad1cf6>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-8923fdad1cf6>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    Q2bins = [0.0,100.0]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def compute_asym(rootdir = \"\",\n",
    "                 target  = \"\",\n",
    "                 runMin = -1,\n",
    "                 runMax = -1,\n",
    "                 runList = [],\n",
    "                 doRunOrdering = True,\n",
    "                 correction = False):\n",
    "    # Check if user both defined a runList and runRange\n",
    "    if(runMin>0 and runMax>0 and runList):\n",
    "        print(\"ERROR: compute_asym must have EITHER a run range OR a run list defined, not both...Aborting...\")\n",
    "        return -1\n",
    "    \n",
    "    # Obtain path to all .root files for analysis\n",
    "    files = get_files(rootdir, target, runMin, runMax, runList, consecutive = doRunOrdering)\n",
    "    if(files==[]):\n",
    "        print(\"ERROR: compute_asym could not find any files. Aborting...\")\n",
    "        return -1\n",
    "    \n",
    "    # List of runs\n",
    "    runs = []\n",
    "    for file in files:\n",
    "        runs.append(get_run_from_root(file))\n",
    "    \n",
    "    # Obtain rcdb file and load as pandas csv\n",
    "    rcdb = get_rcdb(rootdir)\n",
    "    df_rcdb = pd.read_csv(rcdb)\n",
    "    \n",
    "    # Construct A_LL histograms run-by-run\n",
    "    ret = []\n",
    "    for run,file in zip(runs,files):\n",
    "        target=get_colval_from_run(df_rcdb,run,\"Target\")\n",
    "        # Define xbins and Q2bins based on Sebastian's table\n",
    "        xbins,Q2bins=0,0\n",
    "        if(target==\"NH3\"):\n",
    "            xbins = np.unique(np.array(A_LL_proton_sebastian[\"xmin\"].to_list()+A_LL_proton_sebastian[\"xmax\"].to_list()))\n",
    "            Q2bins = np.unique(np.array(A_LL_proton_sebastian[\"Q2min\"].to_list()+A_LL_proton_sebastian[\"Q2max\"].to_list()))\n",
    "        elif(target==\"ND3\"):\n",
    "            xbins = np.unique(np.array(A_LL_deuteron_sebastian[\"xmin\"].to_list()+A_LL_deuteron_sebastian[\"xmax\"].to_list()))\n",
    "            Q2bins = np.unique(np.array(A_LL_deuteron_sebastian[\"Q2min\"].to_list()+A_LL_deuteron_sebastian[\"Q2max\"].to_list()))\n",
    "        else:\n",
    "            xbins = np.array([0.0,1.0])\n",
    "            Q2bins = np.array([0.0,100.0])\n",
    "        if(target!=\"NH3\" and target!=\"ND3\"): # TEMPORARY Oct 12 2022\n",
    "            continue\n",
    "        ret.append(get_A_LL_hist(file,run,df_rcdb,target,xbins,Q2bins,correction))\n",
    "        print(\"Completed {} run\".format(target),run)\n",
    "    print(\"Done\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-browse",
   "metadata": {},
   "source": [
    "# PLOTTING TOOLS (ASYMMETRIES)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign unique markers and colors to array of TGraphErrors\n",
    "def stylize_tgrapherrors(tge):\n",
    "    nMarkers = len(TAttMarkers)\n",
    "    nColors = len(TColors)\n",
    "    nPlots = len(tge)\n",
    "    if(nPlots > nColors * nMarkers):\n",
    "        print(\"ERROR: The number of plots sent to stylize_tgrapherrors is too large (\",nPlots,\">\",nColors*nMarkers,\")...Aborting...\")\n",
    "        return -1\n",
    "    \n",
    "    for i in range(nColors):\n",
    "        color = TColors[i]\n",
    "        for j in range(nMarkers):\n",
    "            marker = TAttMarkers[j]\n",
    "            if(nMarkers*i+j>=nPlots):\n",
    "                return tge\n",
    "            else:\n",
    "                tge[nMarkers*i+j].SetMarkerStyle(marker)\n",
    "                tge[nMarkers*i+j].SetMarkerColor(color)\n",
    "                tge[nMarkers*i+j].SetMarkerColor(color)\n",
    "                tge[nMarkers*i+j].SetMarkerSize(MarkerSize)  \n",
    "    return tge\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From an array of plots, get the minimum and maximum y values\n",
    "# The 'error' parameter is for error bar plots\n",
    "def get_plot_minmax(plotArr,error, expand = 0.1):\n",
    "    plotmin, plotmax = 999,-999\n",
    "    for plot in plotArr:\n",
    "        for point_idx in range(plot.GetN()):\n",
    "            tempUp, tempDown = 0,0\n",
    "            if(error==True):\n",
    "                tempUp = plot.GetPointY(point_idx) + plot.GetErrorY(point_idx)\n",
    "                tempDown = plot.GetPointY(point_idx) - plot.GetErrorY(point_idx)\n",
    "            else:\n",
    "                tempUp = plot.GetPointY(point_idx)\n",
    "                tempDown = tempUp\n",
    "            \n",
    "            if(tempUp>plotmax):\n",
    "                plotmax = tempUp\n",
    "            if(tempDown<plotmin):\n",
    "                plotmin = tempDown\n",
    "                \n",
    "    # Expand range by expand%\n",
    "    plotRange = plotmax-plotmin\n",
    "    exp = plotRange * expand\n",
    "    plotmin = plotmin - 0.5 * exp\n",
    "    plotmax = plotmax + 0.5 * exp\n",
    "    \n",
    "    # Return\n",
    "    return plotmin,plotmax            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-yemen",
   "metadata": {},
   "source": [
    "# TOOLS (TARGET POLARIZATION)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "academic-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_to_dataframe(H,hackJob=False):\n",
    "    runNumberArr = [a[0] for a in H]\n",
    "    TargArr = [a[1] for a in H]\n",
    "    TpolArr = [a[2] for a in H]\n",
    "    HWPArr = [a[3] for a in H]\n",
    "    histArr = [a[4] for a in H]\n",
    "    histwArr = [a[5] for a in H]\n",
    "    fcup_parallelArr = [a[6] for a in H]\n",
    "    fcup_antiparallelArr = [a[7] for a in H]\n",
    "    NpArr = [a[8] for a in H]\n",
    "    NmArr = [a[9] for a in H]\n",
    "    NperrArr = [a[10] for a in H]\n",
    "    NmerrArr = [a[11] for a in H]\n",
    "    NwpArr = [a[12] for a in H]\n",
    "    NwmArr = [a[13] for a in H]\n",
    "    NwperrArr = [a[14] for a in H]\n",
    "    NwmerrArr = [a[15] for a in H]\n",
    "    xbins = np.unique(np.array(A_LL_proton_sebastian[\"xmin\"].to_list()+A_LL_proton_sebastian[\"xmax\"].to_list()))\n",
    "    ybins = np.unique(np.array(A_LL_proton_sebastian[\"Q2min\"].to_list()+A_LL_proton_sebastian[\"Q2max\"].to_list()))\n",
    "    \n",
    "    # Create column names for pandas dataframe\n",
    "    cols = [\"Run\",\"Target\",\"Tpol\",\"HWP\",\"xmin\",\"xmax\",\"x\",\"Q2min\",\"Q2max\",\"Q2\",\"A_LL\",\"A_LL_err\",\"A_LL_wt\",\"A_LL_wt_err\",\"A_||\",\"f\",\"fcup_parallel\",\"fcup_antiparallel\",\"N+\",\"N-\",\"N+err\",\"N-err\",\"n+\",\"n-\",\"n+err\",\"n-err\"]\n",
    "    \n",
    "    # Create Pandas Dataframe\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    # Append rows to dataframe\n",
    "    for r,targ,tpol,hwp,h,hw,Np,Nn,_np,_nm,_nwp,_nwm,_nperr,_nmerr,_nwperr,_nwmerr in zip(runNumberArr, TargArr, TpolArr, HWPArr,histArr,histwArr,\n",
    "                                                                                                        fcup_parallelArr,fcup_antiparallelArr,\n",
    "                                                                                                        NpArr,NmArr,NwpArr,NwmArr,\n",
    "                                                                                                        NperrArr,NmerrArr,NwperrArr,NwmerrArr):\n",
    "        row = []\n",
    "        bin_idx = -1\n",
    "        for xbin_idx in range(h.GetNbinsX()):\n",
    "            for ybin_idx in range(h.GetNbinsY()):\n",
    "                bin_idx+=1\n",
    "                \n",
    "                xl = xbins[xbin_idx]\n",
    "                xr = xbins[xbin_idx+1]\n",
    "                xc = (xl+xr)/2\n",
    "                \n",
    "                yl = ybins[ybin_idx]\n",
    "                yr = ybins[ybin_idx+1]\n",
    "                yc = (yl+yr)/2\n",
    "\n",
    "                a_ll = h.GetBinContent(xbin_idx+1,ybin_idx+1)\n",
    "                a_ll_err = h.GetBinError(xbin_idx+1,ybin_idx+1)\n",
    "\n",
    "                a_ll_wt = hw.GetBinContent(xbin_idx+1,ybin_idx+1)\n",
    "                a_ll_wt_err = hw.GetBinError(xbin_idx+1,ybin_idx+1)\n",
    "    \n",
    "                a_ll_theory = []\n",
    "                if(targ==\"NH3\"):\n",
    "                    a_ll_theory = A_LL_proton_sebastian[(A_LL_proton_sebastian[\"xmin\"]==xl) &\n",
    "                                                        (A_LL_proton_sebastian[\"Q2min\"]==yl)][\"A_LL\"].to_list()\n",
    "                elif(targ==\"ND3\"):\n",
    "                    a_ll_theory = A_LL_deuteron_sebastian[(A_LL_deuteron_sebastian[\"xmin\"]==xl) &\n",
    "                                                        (A_LL_deuteron_sebastian[\"Q2min\"]==yl)][\"A_LL\"].to_list()\n",
    "                else:\n",
    "                    a_ll_theory = [0]\n",
    "                if(a_ll_theory==[]):\n",
    "                    continue # Do not care about x-Q2 bins with no theory A_LL\n",
    "                else:\n",
    "                    a_ll_theory = a_ll_theory[0]\n",
    "                    \n",
    "                if(TargArr[0]==\"NH3\"):\n",
    "                    f = np.round(interp(f_NH3,xc),6)\n",
    "                else:\n",
    "                    f = np.round(interp(f_ND3,xc),6)\n",
    "                \n",
    "                if(hwp==0):\n",
    "                    hwp=\"in\"\n",
    "                else:\n",
    "                    hwp=\"out\"\n",
    "                \n",
    " \n",
    "                row = [r,targ,tpol,hwp,xl,xr,xc,yl,yr,yc,a_ll,a_ll_err,a_ll_wt,a_ll_wt_err,a_ll_theory,\n",
    "                       f,Np,Nn,\n",
    "                       _np[bin_idx],_nm[bin_idx],_nperr[bin_idx],_nmerr[bin_idx],\n",
    "                       _nwp[bin_idx],_nwm[bin_idx],_nwperr[bin_idx],_nwmerr[bin_idx]]\n",
    "                \n",
    "                # Add row\n",
    "                df.loc[len(df.index)] = row\n",
    "\n",
    "    # Return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Pt using Sebastian's bin-by-bin weighing scheme\n",
    "def calc_Pt(nruns,reps,Np,Np_err,Nm,Nm_err,A_th,beamPol,f):\n",
    "\n",
    "    Pt_Arr = []\n",
    "    Pt_err_Arr = []\n",
    "    \n",
    "    for i in range(nruns):\n",
    "        \n",
    "        _s = slice(i*reps,(i+1)*reps)\n",
    "        \n",
    "        numerator = np.sum((Np[_s]-Nm[_s])*A_th[_s]*f[_s])\n",
    "        denominator = np.sum((Np[_s]+Nm[_s])*A_th[_s]*A_th[_s]*f[_s]*f[_s])\n",
    "\n",
    "        numerator_err = np.sqrt(np.sum(  (A_th[_s]*f[_s])**2 * (Np_err[_s]**2+Nm_err[_s]**2)   ) )\n",
    "        denominator_err = np.sqrt(np.sum(  (A_th[_s]*f[_s])**4 * (Np_err[_s]**2+Nm_err[_s]**2) ) )\n",
    "        \n",
    "        Pt_Arr.append(numerator/denominator/beamPol)\n",
    "        Pt_err_Arr.append(np.sqrt(numerator**2*denominator_err**2+denominator**2*numerator_err**2)/beamPol/denominator/denominator)\n",
    "        #Pt_err_Arr.append(1/np.sqrt(     \n",
    "        #                            np.sum((  Np[_s] + Nm[_s] ) * f[_s]**2*A_th[_s]**2)        \n",
    "        #                          )\n",
    "        #                 )\n",
    "        \n",
    "    return Pt_Arr, Pt_err_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sized-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "markerColors=['k','r','b','g','y']\n",
    "markerStyles=['.','o','v','^','<','>','s','P','*','X','x','d']\n",
    "markers = [mc+ms for mc in markerColors for ms in markerStyles]\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "def multigraph(df,beamPol):\n",
    "    \n",
    "    # Extract arrays\n",
    "    runNumberArr = df[\"Run\"].to_numpy()\n",
    "    TargArr = df[\"Target\"].to_list()\n",
    "    #if(TargArr[0]==\"C\"):\n",
    "    #    multigraph_C(df,beamPol)\n",
    "    TpolArr = df[\"Tpol\"].to_numpy()\n",
    "    HWPArr = df[\"HWP\"].to_list()\n",
    "    xminArr = df[\"xmin\"].to_numpy()\n",
    "    xmaxArr = df[\"xmax\"].to_numpy()\n",
    "    xArr = df[\"x\"].to_list()\n",
    "    Q2minArr = df[\"Q2min\"].to_numpy()\n",
    "    Q2maxArr = df[\"Q2max\"].to_numpy()\n",
    "    Q2Arr = df[\"Q2\"].to_list()\n",
    "    A_Arr = df[\"A_LL\"].to_numpy()\n",
    "    A_err_Arr = df[\"A_LL_err\"].to_numpy()\n",
    "    A_wt_Arr = df[\"A_LL_wt\"].to_numpy()\n",
    "    A_wt_err_Arr = df[\"A_LL_wt_err\"].to_numpy()\n",
    "    A_th_Arr = df[\"A_||\"].to_numpy()\n",
    "    dilution_Arr = df[\"f\"].to_numpy()\n",
    "    FCup_parallelArr = df[\"fcup_parallel\"].to_numpy() \n",
    "    FCup_antiparallelArr = df[\"fcup_antiparallel\"].to_numpy() \n",
    "    Np_Arr = df[\"N+\"].to_numpy()\n",
    "    Nm_Arr = df[\"N-\"].to_numpy()\n",
    "    Nwp_Arr = df[\"n+\"].to_numpy()\n",
    "    Nwm_Arr = df[\"n-\"].to_numpy()\n",
    "    Np_err_Arr = df[\"N+err\"].to_numpy()\n",
    "    Nm_err_Arr = df[\"N-err\"].to_numpy()\n",
    "    Nwp_err_Arr = df[\"n+err\"].to_numpy()\n",
    "    Nwm_err_Arr = df[\"n-err\"].to_numpy()\n",
    "    \n",
    "    \n",
    "    # Extract unique arrays (b/c of repetitive vals)\n",
    "    reps = np.sum(TpolArr==TpolArr[0]) # Number of kinematic bins (e.g. xbins)\n",
    "    urunNumberArr = runNumberArr[::reps]\n",
    "    uTargArr = TargArr[::reps]\n",
    "    uTpolArr = TpolArr[::reps]\n",
    "    uHWPArr = HWPArr[::reps]\n",
    "    uFCup_parallelArr = FCup_parallelArr[::reps]\n",
    "    uFCup_antiparallelArr = FCup_antiparallelArr[::reps]\n",
    "    nruns = len(uTargArr)\n",
    "    print(urunNumberArr)\n",
    "    \n",
    "    # Bools for selection\n",
    "    bool_negPol = (uTpolArr<0)\n",
    "    bool_HWPin  = np.array([(hwp==\"in\") for hwp in uHWPArr])\n",
    "    bool_HWPout = np.array([(hwp==\"out\") for hwp in uHWPArr])\n",
    "    \n",
    "    \n",
    "    fig1, axs1 = plt.subplots(1,2,figsize=(20, 10))\n",
    "    axs1[0].ticklabel_format(useOffset=False)\n",
    "    axs1[1].ticklabel_format(useOffset=False)\n",
    "    # Tpol vs. run\n",
    "    axs1[0].plot(urunNumberArr[bool_HWPin],uTpolArr[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "    axs1[0].plot(urunNumberArr[(bool_negPol * bool_HWPin)],-uTpolArr[(bool_negPol * bool_HWPin)],\"r.\")\n",
    "    axs1[0].plot(urunNumberArr[bool_HWPout],uTpolArr[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "    axs1[0].plot(urunNumberArr[(bool_negPol * bool_HWPout)],-uTpolArr[(bool_negPol * bool_HWPout)],\"rx\")\n",
    "    axs1[0].set_xlabel(\"Run\")\n",
    "    axs1[0].set_ylabel(\"Tpol\")\n",
    "    axs1[0].grid()\n",
    "    axs1[0].legend()\n",
    "\n",
    "    # Faraday cup ratio vs. run\n",
    "    uFCup_ratio = (uFCup_parallelArr-uFCup_antiparallelArr)/(uFCup_parallelArr+uFCup_antiparallelArr)\n",
    "    axs1[1].plot(urunNumberArr[bool_HWPin],uFCup_ratio[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "    axs1[1].plot(urunNumberArr[bool_HWPout],uFCup_ratio[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "    axs1[1].set_xlabel(\"Run\")\n",
    "    axs1[1].set_ylabel(\"(FC+  -  FC-)/(FC+  +  FC-)\")\n",
    "    axs1[1].grid()\n",
    "    axs1[1].legend()\n",
    "\n",
    "    # Dilution\n",
    "    fig6,axs6 = plt.subplots(1,1,figsize=(20,10))\n",
    "    Nruns = len(urunNumberArr)\n",
    "    for i,r,xmin,xmax,f in zip(range(len(runNumberArr)),runNumberArr,xminArr,xmaxArr,dilution_Arr):\n",
    "        idx = np.floor(i/reps)\n",
    "        xrange = xmax-xmin\n",
    "        xcenter = (xmax+xmin)/2\n",
    "        x = xcenter\n",
    "        y = f\n",
    "        yerr = 0\n",
    "        \n",
    "        if(i%nruns==0):\n",
    "            axs6.errorbar(x,y,yerr=yerr,fmt=\"ko-\")\n",
    "        else:\n",
    "            continue\n",
    "    axs6.grid()\n",
    "    axs6.set_xlabel(\"x\",fontsize=20)\n",
    "    axs6.set_ylabel(r\"Dilution factor\",fontsize=30)\n",
    "    \n",
    "    # Target Polarization vs. Run Number\n",
    "    Nruns = len(urunNumberArr)\n",
    "    fig8,axs8 = plt.subplots(1,1,figsize=(20,10))\n",
    "    axs8.ticklabel_format(useOffset=False)\n",
    "    Pt_w_Arr, Pt_w_err_Arr = calc_Pt(nruns,reps,Nwp_Arr,Nwp_err_Arr,Nwm_Arr,Nwm_err_Arr,A_th_Arr, beamPol,dilution_Arr)\n",
    "    Pt_Arr, Pt_err_Arr = calc_Pt(nruns,reps,Np_Arr,Np_err_Arr,Nm_Arr,Nm_err_Arr,A_th_Arr, beamPol,dilution_Arr)\n",
    "    \n",
    "    axs8.errorbar(urunNumberArr,Pt_w_Arr,yerr=Pt_w_err_Arr,label=\"FCup weights\",fmt=\"ro-\")\n",
    "    axs8.errorbar(urunNumberArr,Pt_Arr,yerr=Pt_err_Arr,label=\"No FCup weights\",fmt=\"ko-\")\n",
    "    axs8.grid()\n",
    "    axs8.legend()\n",
    "    axs8.set_xlabel(\"Run\",fontsize=20)\n",
    "    axs8.set_ylabel(r\"$P_{t}=\\frac{1}{P_b}\\frac{\\sum_{x,Q^{2}}\\left[(N^{+}-N^{-}) A_{||}(x,Q^{2})f(x)\\right]}{\\sum_{x,Q^2}\\left[(N^{+}+N^{-}) A^{2}_{||}(x,Q^{2})f^{2}(x)\\right]}$\",fontsize=30)\n",
    "    axs8.text(0.15,0.25,r\"$P_b={:.1f}\\%$\".format(100*beamPol),fontsize=25,horizontalalignment='center',\n",
    "     verticalalignment='center',transform=axs8.transAxes)\n",
    "    \n",
    "    fig9,axs9 = plt.subplots(1,1,figsize=(12,10))\n",
    "    rmin = np.amin(urunNumberArr)\n",
    "    rmax = np.amax(urunNumberArr)\n",
    "    axs9.ticklabel_format(useOffset=False)\n",
    "    boolTpolPos = np.array([_t > 0 for _t in _rcdb_Tpol]) * np.array([_r >= rmin and _r <= rmax for _r in _rcdb_run])\n",
    "    boolTpolNeg = np.array([_t < 0 for _t in _rcdb_Tpol]) * np.array([_r >= rmin and _r <= rmax for _r in _rcdb_run])\n",
    "    axs9.errorbar(urunNumberArr,Pt_w_Arr,yerr=Pt_w_err_Arr,label=\"FCup weights\",fmt=\"ro\")\n",
    "    axs9.errorbar(urunNumberArr,Pt_Arr,yerr=Pt_err_Arr,label=\"No FCup weights\",fmt=\"ko\")\n",
    "    axs9.plot(_rcdb_run[boolTpolPos],_rcdb_Tpol[boolTpolPos],\"k*\",label=r\"RCDB Tpol$>$0\",markersize=10,fillstyle='none')\n",
    "    axs9.plot(_rcdb_run[boolTpolNeg],np.abs(_rcdb_Tpol[boolTpolNeg]),\"r*\",label=r\"RCDB Tpol$<$0\",markersize=10,fillstyle='none')\n",
    "    axs9.grid()\n",
    "    axs9.legend()\n",
    "    axs9.set_xlabel(\"Run\",fontsize=20)\n",
    "    axs9.set_ylabel(r\"$P_{t}$\",fontsize=30)\n",
    "    axs9.text(0.15,0.25,r\"$P_b={:.1f}\\%$\".format(100*beamPol),fontsize=25,horizontalalignment='center',\n",
    "     verticalalignment='center',transform=axs9.transAxes)\n",
    "    axs9.set_ylim(0,axs9.get_ylim()[1])\n",
    "    \n",
    "    \n",
    "    # N+ - N-\n",
    "    runs = []\n",
    "    vals = []\n",
    "    errvals = []\n",
    "    for r in urunNumberArr:\n",
    "        runs.append(r)\n",
    "        dff = df[df[\"Run\"]==r]\n",
    "        vals.append(np.sum((dff[\"N+\"]-dff[\"N-\"]))/np.sum((dff[\"N+\"]+dff[\"N-\"])))\n",
    "        errvals.append(2/(np.sum(dff[\"N+\"])+np.sum(dff[\"N-\"]))**2*np.sqrt(np.sum(dff[\"N+\"])**2*np.sum(dff[\"N-\"])+np.sum(dff[\"N-\"])**2*np.sum(dff[\"N+\"])))\n",
    "    fig10,axs10 = plt.subplots(1,1,figsize=(12,10))\n",
    "    axs10.ticklabel_format(useOffset=False)\n",
    "    axs10.errorbar(runs,vals,yerr=errvals,fmt=\"ro\")\n",
    "    axs10.set_xlabel(\"Run\",fontsize=20)\n",
    "    axs10.set_ylabel(r\"$\\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$\",fontsize=20)\n",
    "    axs10.grid()\n",
    "        \n",
    "    # Return stuff\n",
    "    DF = df.copy()\n",
    "    DF[\"Pb\"]=np.ones(reps*nruns)*beamPol\n",
    "    DF[\"Pt\"]=np.repeat(Pt_Arr,reps)\n",
    "    DF[\"Pt_err\"]=np.repeat(Pt_err_Arr,reps)\n",
    "    DF.rename(columns={'Tpol':'Tpol RCDB'}, inplace=True)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multigraph_C(df,beamPol):\n",
    "    \n",
    "    # Extract arrays\n",
    "    runNumberArr = df[\"Run\"].to_numpy()\n",
    "    TargArr = df[\"Target\"].to_list()\n",
    "    TpolArr = df[\"Tpol\"].to_numpy()\n",
    "    HWPArr = df[\"HWP\"].to_list()\n",
    "    xminArr = df[\"xmin\"].to_numpy()\n",
    "    xmaxArr = df[\"xmax\"].to_numpy()\n",
    "    xArr = df[\"x\"].to_list()\n",
    "    Q2minArr = df[\"Q2min\"].to_numpy()\n",
    "    Q2maxArr = df[\"Q2max\"].to_numpy()\n",
    "    Q2Arr = df[\"Q2\"].to_list()\n",
    "    A_Arr = df[\"A_LL\"].to_numpy()\n",
    "    A_err_Arr = df[\"A_LL_err\"].to_numpy()\n",
    "    A_wt_Arr = df[\"A_LL_wt\"].to_numpy()\n",
    "    A_wt_err_Arr = df[\"A_LL_wt_err\"].to_numpy()\n",
    "    A_th_Arr = df[\"A_||\"].to_numpy()\n",
    "    dilution_Arr = df[\"f\"].to_numpy()\n",
    "    FCup_parallelArr = df[\"fcup_parallel\"].to_numpy() \n",
    "    FCup_antiparallelArr = df[\"fcup_antiparallel\"].to_numpy() \n",
    "    Np_Arr = df[\"N+\"].to_numpy()\n",
    "    Nm_Arr = df[\"N-\"].to_numpy()\n",
    "    Nwp_Arr = df[\"n+\"].to_numpy()\n",
    "    Nwm_Arr = df[\"n-\"].to_numpy()\n",
    "    Np_err_Arr = df[\"N+err\"].to_numpy()\n",
    "    Nm_err_Arr = df[\"N-err\"].to_numpy()\n",
    "    Nwp_err_Arr = df[\"n+err\"].to_numpy()\n",
    "    Nwm_err_Arr = df[\"n-err\"].to_numpy()\n",
    "    \n",
    "    \n",
    "    # Extract unique arrays (b/c of repetitive vals)\n",
    "    reps = np.sum(TpolArr==TpolArr[0]) # Number of kinematic bins (e.g. xbins)\n",
    "    urunNumberArr = runNumberArr[::reps]\n",
    "    uTargArr = TargArr[::reps]\n",
    "    uTpolArr = TpolArr[::reps]\n",
    "    uHWPArr = HWPArr[::reps]\n",
    "    uFCup_parallelArr = FCup_parallelArr[::reps]\n",
    "    uFCup_antiparallelArr = FCup_antiparallelArr[::reps]\n",
    "    nruns = len(uTargArr)\n",
    "    print(urunNumberArr)\n",
    "    \n",
    "    # Bools for selection\n",
    "    bool_negPol = (uTpolArr<0)\n",
    "    bool_HWPin  = np.array([(hwp==\"in\") for hwp in uHWPArr])\n",
    "    bool_HWPout = np.array([(hwp==\"out\") for hwp in uHWPArr])\n",
    "    \n",
    "    \n",
    "    fig1, axs1 = plt.subplots(1,2,figsize=(20, 10))\n",
    "    axs1[0].ticklabel_format(useOffset=False)\n",
    "    axs1[1].ticklabel_format(useOffset=False)\n",
    "    # Tpol vs. run\n",
    "    axs1[0].plot(urunNumberArr[bool_HWPin],uTpolArr[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "    axs1[0].plot(urunNumberArr[(bool_negPol * bool_HWPin)],-uTpolArr[(bool_negPol * bool_HWPin)],\"r.\")\n",
    "    axs1[0].plot(urunNumberArr[bool_HWPout],uTpolArr[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "    axs1[0].plot(urunNumberArr[(bool_negPol * bool_HWPout)],-uTpolArr[(bool_negPol * bool_HWPout)],\"rx\")\n",
    "    axs1[0].set_xlabel(\"Run\")\n",
    "    axs1[0].set_ylabel(\"Tpol\")\n",
    "    axs1[0].grid()\n",
    "    axs1[0].legend()\n",
    "\n",
    "    # Faraday cup ratio vs. run\n",
    "    uFCup_ratio = (uFCup_parallelArr-uFCup_antiparallelArr)/(uFCup_parallelArr+uFCup_antiparallelArr)\n",
    "    axs1[1].plot(urunNumberArr[bool_HWPin],uFCup_ratio[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "    axs1[1].plot(urunNumberArr[bool_HWPout],uFCup_ratio[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "    axs1[1].set_xlabel(\"Run\")\n",
    "    axs1[1].set_ylabel(\"(FC+  -  FC-)/(FC+  +  FC-)\")\n",
    "    axs1[1].grid()\n",
    "    axs1[1].legend()\n",
    "    \n",
    "    # N+ - N-\n",
    "    runs = []\n",
    "    vals = []\n",
    "    errvals = []\n",
    "    for r in urunNumberArr:\n",
    "        runs.append(r)\n",
    "        dff = df[df[\"Run\"]==r]\n",
    "        vals.append(np.sum((dff[\"N+\"]-dff[\"N-\"]))/np.sum((dff[\"N+\"]+dff[\"N-\"])))\n",
    "        errvals.append(2/(np.sum(dff[\"N+\"])+np.sum(dff[\"N-\"]))**2*np.sqrt(np.sum(dff[\"N+\"])**2*np.sum(dff[\"N-\"])+np.sum(dff[\"N-\"])**2*np.sum(dff[\"N+\"])))\n",
    "    fig10,axs10 = plt.subplots(1,1,figsize=(12,10))\n",
    "    axs10.ticklabel_format(useOffset=False)\n",
    "    axs10.errorbar(runs,vals,yerr=errvals,fmt=\"ro\")\n",
    "    axs10.set_xlabel(\"Run\",fontsize=20)\n",
    "    axs10.set_ylabel(r\"$\\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$\",fontsize=20)\n",
    "    axs10.grid()\n",
    "        \n",
    "    # Return stuff\n",
    "    DF = df.copy()\n",
    "    DF[\"Pb\"]=np.ones(reps*nruns)*beamPol\n",
    "    DF[\"Pt\"]=np.repeat(Pt_Arr,reps)\n",
    "    DF[\"Pt_err\"]=np.repeat(Pt_err_Arr,reps)\n",
    "    DF.rename(columns={'Tpol':'Tpol RCDB'}, inplace=True)\n",
    "    return DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
