{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sacred-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qg3tuoun because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-handling",
   "metadata": {},
   "source": [
    "# PARAMETERS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "quick-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAttMarkers = [20,21,22,23,33,34,29,24,25,26,32,27,28,30]\n",
    "TColors = [1,2,9,8,6]\n",
    "MarkerSize = 2\n",
    "\n",
    "# Webplotdigitizer using Harut's MC data\n",
    "# https://userweb.jlab.org/~avakian/tmp/2022-SIDIS-Aug8.pdf\n",
    "# A_LL_proton as a function of x\n",
    "# [x,A_LL_proton]\n",
    "A_LL_proton = np.array([\n",
    "[0.11757848013262741, 0.18379497577967974],\n",
    "[0.1926541526284828, 0.2684978538773837],\n",
    "[0.2672720466335098, 0.34164975653604424],\n",
    "[0.3428054976201935, 0.3981517312610664],\n",
    "[0.4178811701160489, 0.4407159649813103],\n",
    "[0.4929568426119043, 0.4885217883139879],\n",
    "[0.5675747366169313, 0.5337541806020067],\n",
    "[0.6426504091127867, 0.602493032329989]])\n",
    "\n",
    "# Webplot digitizer using Harut's MC data\n",
    "# https://userweb.jlab.org/~avakian/tmp/2022-SIDIS-Aug8.pdf\n",
    "# NH3 dilution factor f as a function of x\n",
    "# [x,f]\n",
    "f_NH3 = np.array([\n",
    "[0.117026744250078, 0.177177027261547],\n",
    "[0.12562822371923127, 0.17772179947569455],\n",
    "[0.1342297031883845, 0.17830842392982116],\n",
    "[0.14290937792543915, 0.1788241341617871],\n",
    "[0.15111988105508545, 0.17935517777492244],\n",
    "[0.16003414159584425, 0.17997120009544962],\n",
    "[0.16863562106499752, 0.18047914233841564],\n",
    "[0.17739349106995356, 0.18102689485856938],\n",
    "[0.18583858000330403, 0.1815937981106982],\n",
    "[0.19444005947245727, 0.18207997718887511],\n",
    "[0.20304153894161053, 0.18264986074701012],\n",
    "[0.21195579948236934, 0.18323909763395071],\n",
    "[0.220244497879917, 0.18375614607129687],\n",
    "[0.2286895868132675, 0.1843021232034362],\n",
    "[0.23744745681822355, 0.1848373200515962],\n",
    "[0.245892545751574, 0.18539417876613007],\n",
    "[0.25465041575653, 0.18593523492788716],\n",
    "[0.26325189522568326, 0.1865720820699886],\n",
    "[0.27154059362323096, 0.18699956671377962],\n",
    "[0.2804548541639898, 0.1876155890343068],\n",
    "[0.28905633363314304, 0.1881478055764606],\n",
    "[0.2976578131022963, 0.1887428004785831],\n",
    "[0.3058248744164418, 0.1891597826685512],\n",
    "[0.3151214229336074, 0.1897605829769269],\n",
    "[0.32330586097395325, 0.1902669950806733],\n",
    "[0.3319768473479078, 0.19083420400521306],\n",
    "[0.3406652104480625, 0.19139969796535447],\n",
    "[0.34895390884561023, 0.19186317553552745],\n",
    "[0.35778997411846764, 0.19246054828466017],\n",
    "[0.36670423465922647, 0.19303053314121038],\n",
    "[0.37514932359257697, 0.1935346580333707],\n",
    "[0.3844545604728427, 0.19416775713410842],\n",
    "[0.3927953890489913, 0.19470988729602234],\n",
    "[0.4014229336074451, 0.19526162007378994],\n",
    "[0.4099983479872978, 0.1958152425705318],\n",
    "[0.4188604783494557, 0.19637195733468613],\n",
    "[0.42798325960461825, 0.1969587506195048],\n",
    "[0.43598524201986083, 0.19745540786358048],\n",
    "[0.44562063669793245, 0.19807052442225448],\n",
    "[0.45404834890508267, 0.19859524428929248],\n",
    "[0.46335358578534847, 0.199194861598047],\n",
    "[0.4713381914743907, 0.19967202867159828],\n",
    "[0.48063473999155637, 0.20033235216572196],\n",
    "[0.4895490005323152, 0.20092158905266255],\n",
    "[0.49783769892986285, 0.20136330345804643],\n",
    "[0.5063609831311147, 0.2019388117439748],\n",
    "[0.5150406578681693, 0.202477959230329],\n",
    "[0.5237985278731254, 0.2030684010352613],\n",
    "[0.5322436168064758, 0.20361772634659897],\n",
    "[0.5407473521907523, 0.2041412792085024],\n",
    "[0.5491337946731768, 0.20470968061087763],\n",
    "[0.5576136370589279, 0.20522004809192537],\n",
    "[0.5682134400411167, 0.20591869319120468],\n",
    "[0.57681491951027, 0.20633790868541513],\n",
    "[0.5854163989794232, 0.2069329035875375],\n",
    "[0.5941742689843793, 0.20750576745167867],\n",
    "[0.6026193579177297, 0.20800570711984107],\n",
    "[0.6112208373868829, 0.20856722022998025],\n",
    "[0.6198223168560363, 0.20911199244412781],\n",
    "[0.6284237963251895, 0.209673505554267],\n",
    "[0.6370252757943428, 0.2101931664244271],\n",
    "[0.645235778923989, 0.21074346206795286]])\n",
    "def interp(model,x):\n",
    "    f = interpolate.interp1d(model[:,0], model[:,1], fill_value='extrapolate')\n",
    "    a=f(x)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funny-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_LL_proton_sebastian = pd.read_csv(\"sebastian_A_LL.txt\",sep=\" \",names=[\"xmin\",\"xmax\",\"Q2min\",\"Q2max\",\"A_LL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-scheduling",
   "metadata": {},
   "source": [
    "# HELPER FUNCTIONS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return list of files for analysis\n",
    "# Consecutive flag reorganizes file list with increasing run number\n",
    "def get_files(rootdir = \"\", target = \"\",runMin = -1,runMax = -1, runList = [], consecutive=True, monteCarlo=False):\n",
    "    files = []\n",
    "    runs = []\n",
    "    for path in Path(rootdir).glob(\"{}*/*.root\".format(target)):\n",
    "        runNumber = get_run_from_root(str(path))\n",
    "        if((runMin < 0 and runMax < 0 and runList==[]) or (runNumber >= runMin and runNumber <= runMax) or (runNumber in runList) or monteCarlo==True):\n",
    "            tfile = ROOT.TFile(str(path),\"READ\")\n",
    "            if(tfile.GetListOfKeys().Contains(\"tree_postprocess\")):\n",
    "                files.append(str(path))\n",
    "                runs.append(runNumber)\n",
    "            else:\n",
    "                print(\"ERROR: get_files() found a .root file (run\",runNumber,\") without a tree_reco...skipping...\")\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # Sort by runNumber if specified\n",
    "    if(consecutive==True):\n",
    "        files = [x for y, x in sorted(zip(runs, files))]\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "physical-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab location of rcdb.csv\n",
    "def get_rcdb(rootdir = \"\"):\n",
    "    rcdb_file = rootdir + \"rcdb.csv\"\n",
    "    if(not os.path.exists(rcdb_file)):\n",
    "        print(\"ERROR: get_rcdb() cannot find file\",rcdb_file,\". Aborting...\")\n",
    "        return -1\n",
    "    return rcdb_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "balanced-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the run number from root file name\n",
    "def get_run_from_root(file):\n",
    "    runloc = file.index('run')\n",
    "    start = file.index('-',runloc)\n",
    "    end = file.index('.',runloc)\n",
    "    runNumber = int(file[start+1:end])\n",
    "    return runNumber\n",
    "\n",
    "# Extract other column value based on runNumber\n",
    "def get_colval_from_run(rcdb_csv,runNumber,col = ''):\n",
    "    return rcdb_csv.query('Run=={}'.format(runNumber))[col].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arbitrary-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the rcdb, divide up the file list by polarization\n",
    "def split_pol_files(files, rcdb_csv):\n",
    "    positive_files = []\n",
    "    negative_files = []\n",
    "    for file in files:\n",
    "        runNumber = get_run_from_root(file)\n",
    "        # Grab the value of Tpol for the matching run number\n",
    "        pol=get_colval_from_run(rcdb_csv,runNumber,'Tpol')\n",
    "        if(pol>0):\n",
    "            positive_files.append(file)\n",
    "        elif(pol<0):\n",
    "            negative_files.append(file)\n",
    "        else:\n",
    "            print(\"ERROR: Tpol for run\",runNumber,\"is neither positive or negative. Aborting...\")\n",
    "            return -1\n",
    "    return positive_files,negative_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cutting-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CLAS12Analysis/util/runChargeAsymmetry.csv determine faraday cup accumulation for...\n",
    "# helicity = +1 events\n",
    "# helicity = -1 events\n",
    "\n",
    "def chargeAsymWeights(file,HWP):\n",
    "    \n",
    "    runNumber = get_run_from_root(file)\n",
    "    rCA_df = pd.read_csv('../../../util/runHelicityCounts.csv')\n",
    "    # Check if this run has had chargeAsymmetry calculated for it\n",
    "    if(np.sum(rCA_df['Run']==runNumber)==0):\n",
    "        print(\"ERROR: Run\",runNumber,\"does not appear in CLAS12Analysis/util/runHelicityCounts.csv...Aborting...\")\n",
    "        return -1\n",
    "\n",
    "    # Get accumulated Faraday cup charge for + and - helicity\n",
    "    # Obtained via HEL::scaler in recon banks\n",
    "    fcup_pos = get_colval_from_run(rCA_df,runNumber,'fcup_pos')\n",
    "    fcup_neg = get_colval_from_run(rCA_df,runNumber,'fcup_neg')\n",
    " \n",
    "    npos = get_colval_from_run(rCA_df,runNumber,'npos_recon')\n",
    "    nneg = get_colval_from_run(rCA_df,runNumber,'nneg_recon')\n",
    "    \n",
    "    if(fcup_pos == 0 or fcup_neg == 0):\n",
    "        print(\"ERROR: Zero fcup charge (not all runs currently have this)...skipping\")\n",
    "        return False,False\n",
    "    elif(HWP==1): # HWP out\n",
    "        return fcup_pos, fcup_neg, npos, nneg\n",
    "    elif(HWP==0): # HWP in\n",
    "        return fcup_neg, fcup_pos, nneg, npos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excited-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an RDataFrame Histo1D\n",
    "def hist(df,direction,name,bins,bintype):\n",
    "    zhat = 1 # Pointing from target to CLAS12\n",
    "    histo1d = df.Define(\"vz\",\"abs(vz_e+4.5)\").Filter(\"helicity=={} && p_e > 2.6 && th_e > 0.14 && th_e < 0.611 && vz < 4\".format(zhat*direction)).Histo1D((name,\"\",len(bins)-1,bins),bintype)\n",
    "    return histo1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates average D(y) for each bin\n",
    "# The TH1 function's GetMeanError is used to extract the error in D(y)\n",
    "def hist_Dy(df,name,bins,bintype):\n",
    "    hDy = ROOT.TH1F(\"hDy\",\"hDy\",len(bins)-1,bins) # Binned in desired variable (x, Q2, etc.)\n",
    "    # Within each kinematic binning, we create a D(y) histogram\n",
    "    # The number of bins for this histogram is defined below\n",
    "    nBins_Dy_distribution = 30\n",
    "    for i in range(len(bins)-1):\n",
    "        bL = bins[i]\n",
    "        bR = bins[i+1]\n",
    "        histo1d = df.Define(\"vz\",\"abs(vz_e+4.5)\").Define(\"Dy\",\"y*(1-y/2)/(y*y/2+1-y)\").Filter(\"p_e > 2.6 && th_e > 0.14 && th_e < 0.611 && vz < 4 && {} > {} && {} < {}\".format(bintype,bL,bintype,bR)).Histo1D((name+\"Dy{}\".format(i),\"\",30,0,1),\"Dy\")\n",
    "        hdy = histo1d.GetValue().Clone()\n",
    "        hDy.SetBinContent(i+1,hdy.GetMean())\n",
    "        hDy.SetBinError(i+1,hdy.GetMeanError())\n",
    "    return hDy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAxes(tg,axes):\n",
    "    tg.GetXaxis().SetLimits(axes[0],axes[1])\n",
    "    tg.GetYaxis().SetRangeUser(axes[2],axes[3])\n",
    "    tg.GetYaxis().SetLimits(axes[2],axes[3])\n",
    "    return tg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-strain",
   "metadata": {},
   "source": [
    "# UNWEIGHTED AND WEIGHTED A_LL\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "liked-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given run, compute the A_LL\n",
    "def get_A_LL_hist(file,runNumber,df_rcdb,target,bins,bintype,scaleby=\"FC\"):\n",
    "    # Determine polarization direction of the target\n",
    "    Tpol = 0\n",
    "    targetPol = get_colval_from_run(df_rcdb,runNumber,'Tpol')\n",
    "    HWP = get_colval_from_run(df_rcdb,runNumber,'HWP')\n",
    "    \n",
    "    # ************************************************************\n",
    "    # TEMPORARY PROGRAM AS OF AUGUST 24th 2022\n",
    "    # Set the targetPol of run b/c RCDB is unreliable at the moment\n",
    "    # ************************************************************\n",
    "    \n",
    "    if(runNumber==16406):\n",
    "        targetPol = 0.275 # Not correct, just temp\n",
    "\n",
    "    if(targetPol>0):# Extract \n",
    "        Tpol = 1\n",
    "    else:\n",
    "        Tpol = -1\n",
    "    \n",
    "    if(HWP==0): #If the HWP is in, artificially flip Tpol sign\n",
    "        Tpol = Tpol * -1\n",
    "    \n",
    "    # Get accumulated Faraday cup charge for + and - helicity\n",
    "    fcup_pos, fcup_neg,npos_recon,nneg_recon = chargeAsymWeights(file,HWP)\n",
    "    if(fcup_pos==False):\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Create RDataframe from file\n",
    "    ROOT.EnableImplicitMT()\n",
    "    df = ROOT.RDataFrame(\"tree_postprocess\",file)\n",
    "    \n",
    "    # Create histograms for anti-parallel/parallel events\n",
    "    h_ap = hist(df,-Tpol,\"h_{}_antiparallel\".format(runNumber),bins,bintype)\n",
    "    h_p = hist(df,Tpol,\"h_{}_parallel\".format(runNumber),bins,bintype)\n",
    "    \n",
    "    # Create D(y) histogram\n",
    "    h_Dy = hist_Dy(df,\"h_{}.format(runNumber)\",bins,bintype)\n",
    "    \n",
    "    # Process histograms (from Histo1D --> TH1D)\n",
    "    H_ap = h_ap.GetValue().Clone()\n",
    "    H_p = h_p.GetValue().Clone()\n",
    "    Hw_ap = h_ap.GetValue().Clone() # To be weighted by beam Charge Asym\n",
    "    Hw_p = h_p.GetValue().Clone()   # To be weighted by beam Charge Asym\n",
    "    H_Dy = h_Dy.Clone()\n",
    "    \n",
    "    H_ap.Sumw2()\n",
    "    H_p.Sumw2()\n",
    "    Hw_ap.Sumw2()\n",
    "    Hw_p.Sumw2()\n",
    "    H_Dy.Sumw2()\n",
    "    \n",
    "    # Weigh histograms by helicity counts\n",
    "    # MIGHT'VE MADE A MISTAKE HERE\n",
    "    # Edited 9/11/2022\n",
    "    \n",
    "    if(Tpol==1):\n",
    "        Hw_ap.Scale(1/fcup_neg)\n",
    "        Hw_p.Scale(1/fcup_pos)\n",
    "    else:\n",
    "        Hw_ap.Scale(1/fcup_pos)\n",
    "        Hw_p.Scale(1/fcup_neg)\n",
    "    \n",
    "    \n",
    "    # Grab N+ and N- along with their errors\n",
    "    N_p = [H_p.GetBinContent(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    N_m = [H_ap.GetBinContent(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    Nw_p = [Hw_p.GetBinContent(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    Nw_m = [Hw_ap.GetBinContent(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    \n",
    "    N_err_p = [H_p.GetBinError(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    N_err_m = [H_ap.GetBinError(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    Nw_err_p = [Hw_p.GetBinError(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    Nw_err_m = [Hw_ap.GetBinError(i+1) for i in range(H_p.GetNbinsX())]\n",
    "    \n",
    "    # Scale by float to avoid division issues\n",
    "    H_ap.Scale(1.0)\n",
    "    H_p.Scale(1.0)\n",
    "    \n",
    "    # Create numerator and denominator histogram\n",
    "    H_numerator = H_p.Clone()\n",
    "    H_denominator = H_p.Clone()\n",
    "    Hw_numerator = Hw_p.Clone()\n",
    "    Hw_denominator = Hw_p.Clone()\n",
    "    \n",
    "    # Construct numerator and denominator of asymmetry\n",
    "    H_numerator.Add(H_ap,-1)\n",
    "    H_denominator.Add(H_ap,1)\n",
    "    Hw_numerator.Add(Hw_ap,-1)\n",
    "    Hw_denominator.Add(Hw_ap,1)\n",
    "    \n",
    "    # Divide numerator and denominator\n",
    "    H = H_numerator.Clone()\n",
    "    H.Divide(H_denominator)\n",
    "    Hw = Hw_numerator.Clone()\n",
    "    Hw.Divide(Hw_denominator)\n",
    "    \n",
    "    # Label Histogram\n",
    "    H.SetTitle(\"{} asymmetries RG-C;{};\".format(target,bintype)+\"(N^{+}-N^{-})/(N^{+}+N^{-})\")\n",
    "    Hw.SetTitle(\"{} asymmetries RG-C;{};\".format(target,bintype)+\"(L^{-}N^{+}-L^{+}N^{-})/(L^{-}N^{+}+L^{+}N^{-})\")\n",
    "    \n",
    "    # Return run and H\n",
    "    return [runNumber,target,targetPol,HWP,H.Clone(),Hw.Clone(),fcup_pos,fcup_neg,npos_recon,nneg_recon,N_p,N_m,N_err_p,N_err_m,Nw_p,Nw_m,Nw_err_p,Nw_err_m,H_Dy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-accordance",
   "metadata": {},
   "source": [
    "# MAIN CODE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cheap-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_asym(rootdir = \"\",\n",
    "                 target  = \"\",\n",
    "                 bins = np.array([]),\n",
    "                 bintype = \"\",\n",
    "                 runMin = -1,\n",
    "                 runMax = -1,\n",
    "                 runList = [],\n",
    "                 doRunOrdering = True,\n",
    "                 scaleby=\"FC\"):\n",
    "    # Check if user both defined a runList and runRange\n",
    "    if(runMin>0 and runMax>0 and runList):\n",
    "        print(\"ERROR: compute_asym must have EITHER a run range OR a run list defined, not both...Aborting...\")\n",
    "        return -1\n",
    "    \n",
    "    # Obtain path to all .root files for analysis\n",
    "    files = get_files(rootdir, target, runMin, runMax, runList, consecutive = doRunOrdering)\n",
    "    if(files==[]):\n",
    "        print(\"ERROR: compute_asym could not find any files. Aborting...\")\n",
    "        return -1\n",
    "    \n",
    "    # List of runs\n",
    "    runs = []\n",
    "    for file in files:\n",
    "        runs.append(get_run_from_root(file))\n",
    "    \n",
    "    # Obtain rcdb file and load as pandas csv\n",
    "    rcdb = get_rcdb(rootdir)\n",
    "    df_rcdb = pd.read_csv(rcdb)\n",
    "    \n",
    "\n",
    "    # Construct A_LL histograms run-by-run\n",
    "    ret = []\n",
    "    for run,file in zip(runs,files):\n",
    "        ret.append(get_A_LL_hist(file,run,df_rcdb,target,bins,bintype,scaleby))\n",
    "        print(\"Completed run\",run)\n",
    "    print(\"Done\")\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-europe",
   "metadata": {},
   "source": [
    "# PLOTTING TOOLS (ASYMMETRIES)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign unique markers and colors to array of TGraphErrors\n",
    "def stylize_tgrapherrors(tge):\n",
    "    nMarkers = len(TAttMarkers)\n",
    "    nColors = len(TColors)\n",
    "    nPlots = len(tge)\n",
    "    if(nPlots > nColors * nMarkers):\n",
    "        print(\"ERROR: The number of plots sent to stylize_tgrapherrors is too large (\",nPlots,\">\",nColors*nMarkers,\")...Aborting...\")\n",
    "        return -1\n",
    "    \n",
    "    for i in range(nColors):\n",
    "        color = TColors[i]\n",
    "        for j in range(nMarkers):\n",
    "            marker = TAttMarkers[j]\n",
    "            if(nMarkers*i+j>=nPlots):\n",
    "                return tge\n",
    "            else:\n",
    "                tge[nMarkers*i+j].SetMarkerStyle(marker)\n",
    "                tge[nMarkers*i+j].SetMarkerColor(color)\n",
    "                tge[nMarkers*i+j].SetMarkerColor(color)\n",
    "                tge[nMarkers*i+j].SetMarkerSize(MarkerSize)  \n",
    "    return tge\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From an array of plots, get the minimum and maximum y values\n",
    "# The 'error' parameter is for error bar plots\n",
    "def get_plot_minmax(plotArr,error, expand = 0.1):\n",
    "    plotmin, plotmax = 999,-999\n",
    "    for plot in plotArr:\n",
    "        for point_idx in range(plot.GetN()):\n",
    "            tempUp, tempDown = 0,0\n",
    "            if(error==True):\n",
    "                tempUp = plot.GetPointY(point_idx) + plot.GetErrorY(point_idx)\n",
    "                tempDown = plot.GetPointY(point_idx) - plot.GetErrorY(point_idx)\n",
    "            else:\n",
    "                tempUp = plot.GetPointY(point_idx)\n",
    "                tempDown = tempUp\n",
    "            \n",
    "            if(tempUp>plotmax):\n",
    "                plotmax = tempUp\n",
    "            if(tempDown<plotmin):\n",
    "                plotmin = tempDown\n",
    "                \n",
    "    # Expand range by expand%\n",
    "    plotRange = plotmax-plotmin\n",
    "    exp = plotRange * expand\n",
    "    plotmin = plotmin - 0.5 * exp\n",
    "    plotmax = plotmax + 0.5 * exp\n",
    "    \n",
    "    # Return\n",
    "    return plotmin,plotmax            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-service",
   "metadata": {},
   "source": [
    "# TOOLS (TARGET POLARIZATION)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fantastic-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_to_dataframe(H):\n",
    "    runNumberArr = [a[0] for a in H]\n",
    "    TargArr = [a[1] for a in H]\n",
    "    TpolArr = [a[2] for a in H]\n",
    "    HWPArr = [a[3] for a in H]\n",
    "    histArr = [a[4] for a in H]\n",
    "    histwArr = [a[5] for a in H]\n",
    "    fcup_posArr = [a[6] for a in H]\n",
    "    fcup_negArr = [a[7] for a in H]\n",
    "    nposArr = [a[8] for a in H]\n",
    "    nnegArr = [a[9] for a in H]\n",
    "    NpArr = [a[10] for a in H]\n",
    "    NmArr = [a[11] for a in H]\n",
    "    NperrArr = [a[12] for a in H]\n",
    "    NmerrArr = [a[13] for a in H]\n",
    "    NwpArr = [a[14] for a in H]\n",
    "    NwmArr = [a[15] for a in H]\n",
    "    NwperrArr = [a[16] for a in H]\n",
    "    NwmerrArr = [a[17] for a in H]\n",
    "    histDyArr = [a[18] for a in H]\n",
    "    \n",
    "    # Create column names for pandas dataframe\n",
    "    cols = [\"Run\",\"Target\",\"Tpol\",\"HWP\",\"binType\",\"min\",\"max\"]\n",
    "    xtitle = histArr[0].GetXaxis().GetTitle()\n",
    "    cols.extend([\"A_LL\",\"A_LL_err\",\"A_LL_wt\",\"A_LL_wt_err\",\"A_LL_theory\",\"D\",\"D_err\",\"f\",\"fcup_pos\",\"fcup_neg\",\"npos_recon\",\"nneg_recon\",\"N+\",\"N-\",\"N+err\",\"N-err\",\"n+\",\"n-\",\"n+err\",\"n-err\"])\n",
    "    \n",
    "    # Create Pandas Dataframe\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    # Append rows to dataframe\n",
    "    for r,targ,tpol,hwp,h,hw,Np,Nn,npos,nneg,_np,_nm,_nwp,_nwm,_nperr,_nmerr,_nwperr,_nwmerr,_dy in zip(runNumberArr, TargArr, TpolArr, HWPArr,histArr,histwArr,\n",
    "                                                                                                        fcup_posArr,fcup_negArr,nposArr,nnegArr,\n",
    "                                                                                                        NpArr,NmArr,NwpArr,NwmArr,\n",
    "                                                                                                        NperrArr,NmerrArr,NwperrArr,NwmerrArr,histDyArr):\n",
    "        row = []\n",
    "        for bin_idx in range(h.GetNbinsX()):\n",
    "            bc = h.GetBinCenter(bin_idx+1)\n",
    "            bw = h.GetBinWidth(bin_idx+1)\n",
    "            bl = bc-0.5*bw\n",
    "            br = bc+0.5*bw\n",
    "            \n",
    "            a_ll = h.GetBinContent(bin_idx+1)\n",
    "            a_ll_err = h.GetBinError(bin_idx+1)\n",
    "            \n",
    "            a_ll_wt = hw.GetBinContent(bin_idx+1)\n",
    "            a_ll_wt_err = hw.GetBinError(bin_idx+1)\n",
    "            \n",
    "            a_ll_theory = interp(A_LL_proton,bc)\n",
    "            \n",
    "            D = _dy.GetBinContent(bin_idx+1)\n",
    "            Derr = _dy.GetBinError(bin_idx+1)\n",
    "            \n",
    "            f = np.round(interp(f_NH3,bc),6)\n",
    "            \n",
    "            if(hwp==0):\n",
    "                hwp=\"in\"\n",
    "            else:\n",
    "                hwp=\"out\"\n",
    "            row = [r,targ,tpol,hwp,xtitle,bl,br,a_ll,a_ll_err,a_ll_wt,a_ll_wt_err,a_ll_theory,\n",
    "                   D,Derr,f,Np,Nn,npos,nneg,\n",
    "                   _np[bin_idx],_nm[bin_idx],_nperr[bin_idx],_nmerr[bin_idx],\n",
    "                   _nwp[bin_idx],_nwm[bin_idx],_nwperr[bin_idx],_nwmerr[bin_idx]]\n",
    "            \n",
    "            # Add row\n",
    "            df.loc[len(df.index)] = row\n",
    "    \n",
    "    # Return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Pt using Sebastian's bin-by-bin weighing scheme\n",
    "def calc_Pt(xminArr,xmaxArr,nruns,reps,Np,Np_err,Nm,Nm_err,A_th,beamPol,D,D_err,f):\n",
    "\n",
    "    xcenterArr = (xmaxArr+xminArr)/2\n",
    "    \n",
    "    Pt_Arr = []\n",
    "    Pt_err_Arr = []\n",
    "    \n",
    "    for i in range(nruns):\n",
    "        \n",
    "        _s = slice(i*reps,(i+1)*reps)\n",
    "        \n",
    "        numerator = np.sum((Np[_s]-Nm[_s])*A_th[_s]*D[_s]*f[_s])\n",
    "        denominator = np.sum((Np[_s]+Nm[_s])*A_th[_s]*A_th[_s]*D[_s]*D[_s]*f[_s]*f[_s])\n",
    "\n",
    "        numerator_err = np.sqrt(np.sum(  (A_th[_s]*f[_s])**2 * (D[_s]**2*Np_err[_s]**2+D[_s]**2*Nm_err[_s]**2+(Np[_s]-Nm[_s])**2*D_err[_s]**2)     ))\n",
    "        denominator_err = np.sqrt(np.sum(  (A_th[_s]*f[_s])**4 * (D[_s]**4*Np_err[_s]**2+D[_s]**4*Nm_err[_s]**2+4*(Np[_s]+Nm[_s])**2*D[_s]**2*D_err[_s]**2)     ))\n",
    "        \n",
    "        Pt_Arr.append(numerator/denominator/beamPol)\n",
    "        Pt_err_Arr.append(np.sqrt(numerator**2*denominator_err**2+denominator**2*numerator_err**2)/beamPol/denominator/denominator)\n",
    "\n",
    "    return Pt_Arr, Pt_err_Arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "returning-event",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b93afbbb5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m   \u001b[0;34m:\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'font'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmarkerColors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmarkerStyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'P'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "font = {'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "markerColors=['k','r','b','g','y']\n",
    "markerStyles=['.','o','v','^','<','>','s','P','*','X','x','d']\n",
    "markers = [mc+ms for mc in markerColors for ms in markerStyles]\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "def multigraph(df,beamPol,scaleby=\"FC\"):\n",
    "    \n",
    "    # Extract arrays\n",
    "    runNumberArr = df[\"Run\"].to_numpy()\n",
    "    TargArr = df[\"Target\"].to_list()\n",
    "    TpolArr = df[\"Tpol\"].to_numpy()\n",
    "    HWPArr = df[\"HWP\"].to_list()\n",
    "    binTypeArr = df[\"binType\"].to_list()\n",
    "    xminArr = df[\"min\"].to_numpy()\n",
    "    xmaxArr = df[\"max\"].to_numpy()\n",
    "    A_Arr = df[\"A_LL\"].to_numpy()\n",
    "    A_err_Arr = df[\"A_LL_err\"].to_numpy()\n",
    "    A_wt_Arr = df[\"A_LL_wt\"].to_numpy()\n",
    "    A_wt_err_Arr = df[\"A_LL_wt_err\"].to_numpy()\n",
    "    A_th_Arr = df[\"A_LL_theory\"].to_numpy()\n",
    "    D_Arr = df[\"D\"].to_numpy()\n",
    "    D_err_Arr = df[\"D_err\"].to_numpy()\n",
    "    dilution_Arr = df[\"f\"].to_numpy()\n",
    "    FCup_posArr = df[\"fcup_pos\"].to_numpy() \n",
    "    FCup_negArr = df[\"fcup_neg\"].to_numpy() \n",
    "    npos_reconArr = df[\"npos_recon\"].to_numpy()\n",
    "    nneg_reconArr = df[\"nneg_recon\"].to_numpy()\n",
    "    Np_Arr = df[\"N+\"].to_numpy()\n",
    "    Nm_Arr = df[\"N-\"].to_numpy()\n",
    "    Nwp_Arr = df[\"n+\"].to_numpy()\n",
    "    Nwm_Arr = df[\"n-\"].to_numpy()\n",
    "    Np_err_Arr = df[\"N+err\"].to_numpy()\n",
    "    Nm_err_Arr = df[\"N-err\"].to_numpy()\n",
    "    Nwp_err_Arr = df[\"n+err\"].to_numpy()\n",
    "    Nwm_err_Arr = df[\"n-err\"].to_numpy()\n",
    "    \n",
    "    # Extract unique arrays (b/c of repetitive vals)\n",
    "    reps = np.sum(TpolArr==TpolArr[0]) # Number of kinematic bins (e.g. xbins)\n",
    "    urunNumberArr = runNumberArr[::reps]\n",
    "    uTargArr = TargArr[::reps]\n",
    "    uTpolArr = TpolArr[::reps]\n",
    "    uHWPArr = HWPArr[::reps]\n",
    "    uFCup_posArr = FCup_posArr[::reps]\n",
    "    uFCup_negArr = FCup_negArr[::reps]\n",
    "    unpos_reconArr = npos_reconArr[::reps]\n",
    "    unneg_reconArr = nneg_reconArr[::reps]\n",
    "    nruns = len(uTargArr)\n",
    "\n",
    "    \n",
    "    # Bools for selection\n",
    "    bool_negPol = (uTpolArr<0)\n",
    "    bool_HWPin  = np.array([(hwp==\"in\") for hwp in uHWPArr])\n",
    "    bool_HWPout = np.array([(hwp==\"out\") for hwp in uHWPArr])\n",
    "    \n",
    "    \n",
    "    fig1, axs1 = plt.subplots(1,2,figsize=(20, 10))\n",
    "    # Tpol vs. run\n",
    "    axs1[0].plot(urunNumberArr[bool_HWPin],uTpolArr[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "    axs1[0].plot(urunNumberArr[(bool_negPol * bool_HWPin)],-uTpolArr[(bool_negPol * bool_HWPin)],\"r.\")\n",
    "    axs1[0].plot(urunNumberArr[bool_HWPout],uTpolArr[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "    axs1[0].plot(urunNumberArr[(bool_negPol * bool_HWPout)],-uTpolArr[(bool_negPol * bool_HWPout)],\"rx\")\n",
    "    axs1[0].set_xlabel(\"Run\")\n",
    "    axs1[0].set_ylabel(\"Tpol\")\n",
    "    axs1[0].grid()\n",
    "    axs1[0].legend()\n",
    "    \n",
    "    if(scaleby==\"FC\"):\n",
    "        # Faraday cup ratio vs. run\n",
    "        uFCup_ratio = (uFCup_posArr-uFCup_negArr)/(uFCup_posArr+uFCup_negArr)\n",
    "        axs1[1].plot(urunNumberArr[bool_HWPin],uFCup_ratio[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "        axs1[1].plot(urunNumberArr[bool_HWPout],uFCup_ratio[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "        axs1[1].set_xlabel(\"Run\")\n",
    "        axs1[1].set_ylabel(\"(FC+  -  FC-)/(FC+  +  FC-)\")\n",
    "        axs1[1].grid()\n",
    "        axs1[1].legend()\n",
    "    elif(scaleby==\"RECON\"):\n",
    "        # Helicity count ratio vs. run\n",
    "        uHel_ratio = (unpos_reconArr-unneg_reconArr)/(unpos_reconArr+unneg_reconArr)\n",
    "        axs1[1].plot(urunNumberArr[bool_HWPin],uHel_ratio[bool_HWPin],\"k.\",label=\"HWP in\")\n",
    "        axs1[1].plot(urunNumberArr[bool_HWPout],uHel_ratio[bool_HWPout],\"kx\",label=\"HWP out\")\n",
    "        axs1[1].set_xlabel(\"Run\")\n",
    "        axs1[1].set_ylabel(r\"($N_{r}$+  -  $N_{r}$-)/($N_{r}$+  +  $N_{r}$-)\")\n",
    "        axs1[1].grid()\n",
    "        axs1[1].legend()\n",
    "    \n",
    "    # Unweighted A_LL\n",
    "    fig2,axs2 = plt.subplots(1,1,figsize=(20,10))\n",
    "    Nruns = len(urunNumberArr)\n",
    "    for i,r,xmin,xmax,a_ll,a_ll_err in zip(range(len(runNumberArr)),runNumberArr,xminArr,xmaxArr,A_Arr,A_err_Arr):\n",
    "        idx = np.floor(i/reps)\n",
    "        xrange = xmax-xmin\n",
    "        xcenter = (xmax+xmin)/2\n",
    "        xl = xcenter-xrange/4\n",
    "        xr = xcenter+xrange/4\n",
    "        x = xl+idx*(xr-xl)/Nruns\n",
    "        y = a_ll\n",
    "        yerr = a_ll_err\n",
    "        \n",
    "        if(i%reps==0):\n",
    "            axs2.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)],label=str(r))\n",
    "        else:\n",
    "            axs2.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)])\n",
    "    axs2.grid()\n",
    "    axs2.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs2.set_ylabel(r\"Unweighted $A_{LL} = \\frac{N^{+}-N^{-}}{N^{+}+N^{-}}$\",fontsize=30)\n",
    "    axs2.legend(ncol=4)\n",
    "    \n",
    "    # Weighted A_LL\n",
    "    fig3,axs3 = plt.subplots(1,1,figsize=(20,10))\n",
    "    for i,r,xmin,xmax,a_ll,a_ll_err in zip(range(len(runNumberArr)),runNumberArr,xminArr,xmaxArr,A_wt_Arr,A_wt_err_Arr):\n",
    "        idx = np.floor(i/reps)\n",
    "        xrange = xmax-xmin\n",
    "        xcenter = (xmax+xmin)/2\n",
    "        xl = xcenter-xrange/4\n",
    "        xr = xcenter+xrange/4\n",
    "        x = xl+idx*(xr-xl)/Nruns\n",
    "        y = a_ll\n",
    "        yerr = a_ll_err\n",
    "        \n",
    "        if(i%reps==0):\n",
    "            axs3.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)],label=str(r))\n",
    "        else:\n",
    "            axs3.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)])\n",
    "    axs3.grid()\n",
    "    axs3.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs3.set_ylabel(r\"Weighted $A_{LL} = \\frac{L^{-}N^{+}-L^{+}N^{-}}{L^{-}N^{+}+L^{+}N^{-}}$\",fontsize=30)\n",
    "    axs3.legend(ncol=4)\n",
    "    \n",
    "    # Theory A_LL\n",
    "    fig4,axs4 = plt.subplots(1,1,figsize=(20,10))\n",
    "    x = np.linspace(0.05,0.7,100)\n",
    "    y = np.array([interp(A_LL_proton,X) for X in x])\n",
    "    axs4.plot(x,y,\"k-\",label=\"Extrapolation\")\n",
    "    axs4.plot(A_LL_proton[:,0],A_LL_proton[:,1],\"ro\",label=\"Harut data\",markersize=10)\n",
    "    axs4.grid()\n",
    "    axs4.legend()\n",
    "    axs4.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs4.set_ylabel(r\"Theory $A_{LL}$\",fontsize=30)\n",
    "    \n",
    "    # Depolarization\n",
    "    fig5,axs5 = plt.subplots(1,1,figsize=(20,10))\n",
    "    Nruns = len(urunNumberArr)\n",
    "    for i,r,xmin,xmax,dy,dye in zip(range(len(runNumberArr)),runNumberArr,xminArr,xmaxArr,D_Arr,D_err_Arr):\n",
    "        idx = np.floor(i/reps)\n",
    "        xrange = xmax-xmin\n",
    "        xcenter = (xmax+xmin)/2\n",
    "        xl = xcenter-xrange/4\n",
    "        xr = xcenter+xrange/4\n",
    "        x = xl+idx*(xr-xl)/Nruns\n",
    "        y = dy\n",
    "        yerr = dye\n",
    "        \n",
    "        if(i%reps==0):\n",
    "            axs5.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)],label=str(r))\n",
    "        else:\n",
    "            axs5.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)])\n",
    "    axs5.grid()\n",
    "    axs5.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs5.set_ylabel(r\"Average D(y)\",fontsize=30)\n",
    "    axs5.legend(ncol=4)\n",
    "    \n",
    "    \n",
    "    # Dilution\n",
    "    fig6,axs6 = plt.subplots(1,1,figsize=(20,10))\n",
    "    Nruns = len(urunNumberArr)\n",
    "    for i,r,xmin,xmax,f in zip(range(len(runNumberArr)),runNumberArr,xminArr,xmaxArr,dilution_Arr):\n",
    "        idx = np.floor(i/reps)\n",
    "        xrange = xmax-xmin\n",
    "        xcenter = (xmax+xmin)/2\n",
    "        x = xcenter\n",
    "        y = f\n",
    "        yerr = 0\n",
    "        \n",
    "        if(i%nruns==0):\n",
    "            axs6.errorbar(x,y,yerr=yerr,fmt=\"ko-\")\n",
    "        else:\n",
    "            continue\n",
    "    axs6.grid()\n",
    "    axs6.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs6.set_ylabel(r\"Dilution factor\",fontsize=30)\n",
    "    \n",
    "    # Pt version 1 (bin-by-bin)\n",
    "    fig7,axs7 = plt.subplots(1,1,figsize=(20,10))\n",
    "    for i,r,xmin,xmax,a_ll,a_ll_err,a_ll_th,dy,f in zip(range(len(runNumberArr)),runNumberArr,xminArr,xmaxArr,A_wt_Arr,A_wt_err_Arr,A_th_Arr,D_Arr,dilution_Arr):\n",
    "        idx = np.floor(i/reps)\n",
    "        xrange = xmax-xmin\n",
    "        xcenter = (xmax+xmin)/2\n",
    "        xl = xcenter-xrange/4\n",
    "        xr = xcenter+xrange/4\n",
    "        x = xl+idx*(xr-xl)/Nruns\n",
    "        y = a_ll/(beamPol*dy*f*a_ll_th)\n",
    "        yerr =a_ll_err/(beamPol*dy*f*a_ll_th)\n",
    "        \n",
    "        if(i%reps==0):\n",
    "            axs7.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)],label=str(r))\n",
    "        else:\n",
    "            axs7.errorbar(x,y,yerr=yerr,fmt=markers[int(idx)])\n",
    "    axs7.grid()\n",
    "    axs7.legend(ncol=4)\n",
    "    axs7.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs7.set_ylabel(r\"$P_{t}=A_{LL}^{RAW}/(P_b*D(y)*f*A_{LL}^{TH})$\",fontsize=30)\n",
    "    axs7.text(0.4,0.25,r\"$P_b={:.1f}\\%$\".format(100*beamPol),fontsize=25)\n",
    "    \n",
    "    # Pt version 2 (Sebastian's scheme)\n",
    "    fig8,axs8 = plt.subplots(1,1,figsize=(20,10))\n",
    "    \n",
    "    Pt_w_Arr, Pt_w_err_Arr = calc_Pt(xminArr,xmaxArr,nruns,reps,Nwp_Arr,Nwp_err_Arr,Nwm_Arr,Nwm_err_Arr,A_th_Arr, 0.83, D_Arr, D_err_Arr,dilution_Arr)\n",
    "    Pt_Arr, Pt_err_Arr = calc_Pt(xminArr,xmaxArr,nruns,reps,Np_Arr,Np_err_Arr,Nm_Arr,Nm_err_Arr,A_th_Arr, 0.83, D_Arr, D_err_Arr,dilution_Arr)\n",
    "    \n",
    "    axs8.errorbar(urunNumberArr,Pt_w_Arr,yerr=Pt_w_err_Arr,label=\"FCup weights\",fmt=\"ro-\")\n",
    "    axs8.errorbar(urunNumberArr,Pt_Arr,yerr=Pt_err_Arr,label=\"No FCup weights\",fmt=\"ko-\")\n",
    "    \n",
    "    axs8.grid()\n",
    "    axs8.legend()\n",
    "    axs8.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs8.set_ylabel(r\"$P_{t}=\\frac{1}{P_b}\\frac{\\sum_x\\left[(N^{+}-N^{-}) A_{th}(x)\\bar{D(y)}f(x)\\right]}{\\sum_x\\left[(N^{+}+N^{-}) A^{2}_{th}(x)\\bar{D(y)}^{2}f^{2}(x)\\right]}$\",fontsize=30)\n",
    "    axs8.text(0.55,0.55,r\"$P_b={:.1f}\\%$\".format(100*beamPol),fontsize=25,horizontalalignment='center',\n",
    "     verticalalignment='center',transform=axs8.transAxes)\n",
    "    \n",
    "    # Pt version 2 (Sebastian's scheme) but SMALL\n",
    "    fig9,axs9 = plt.subplots(1,1,figsize=(10,10))\n",
    "    \n",
    "    Pt_Arr, Pt_err_Arr = calc_Pt(xminArr,xmaxArr,nruns,reps,Np_Arr,Np_err_Arr,Nm_Arr,Nm_err_Arr,A_th_Arr, 0.83, D_Arr, D_err_Arr,dilution_Arr)\n",
    "    \n",
    "    axs9.errorbar(urunNumberArr,Pt_Arr,yerr=Pt_err_Arr,label=\"No FCup weights\",fmt=\"ko-\")\n",
    "    \n",
    "    axs9.grid()\n",
    "    axs9.legend()\n",
    "    axs9.set_xlabel(binTypeArr[0],fontsize=20)\n",
    "    axs9.set_ylabel(r\"$P_{t}=\\frac{1}{P_b}\\frac{\\sum_x\\left[(N^{+}-N^{-}) A_{th}(x)\\bar{D(y)}f(x)\\right]}{\\sum_x\\left[(N^{+}+N^{-}) A^{2}_{th}(x)\\bar{D(y)}^{2}f^{2}(x)\\right]}$\",fontsize=30)\n",
    "    axs9.text(0.55,0.8,r\"$P_b={:.1f}\\%$\".format(100*beamPol),fontsize=25,horizontalalignment='center',\n",
    "     verticalalignment='top',transform=axs9.transAxes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return stuff\n",
    "    DF = df\n",
    "    DF = DF.drop(['npos_recon'],axis=1)\n",
    "    DF = DF.drop(['nneg_recon'],axis=1)\n",
    "    DF[\"Pb\"]=np.ones(reps*nruns)*beamPol\n",
    "    DF[\"Pt\"]=np.repeat(Pt_Arr,reps)\n",
    "    DF[\"Pt_err\"]=np.repeat(Pt_err_Arr,reps)\n",
    "    DF.rename(columns={'Tpol':'Tpol RCDB'}, inplace=True)\n",
    "    DF = DF.round({'f' : 4})\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-headline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
